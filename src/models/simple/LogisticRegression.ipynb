{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input, Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import plot_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_0 = pd.read_csv(r'C:\\Users\\darias\\Desktop\\news_0.csv',  sep=\";\", decimal=\",\", \n",
    "                   skiprows=[1,2,3,4], low_memory=False, on_bad_lines='skip').sort_values(by=[\"CODE\"])\n",
    "news_0['class'] = 0\n",
    "\n",
    "news_1 = pd.read_csv(r'C:\\Users\\darias\\Desktop\\news_1.csv',  sep=\";\", decimal=\",\", \n",
    "                   skiprows=[1,2,3,4], low_memory=False, on_bad_lines='skip').sort_values(by=[\"CODE\"])\n",
    "news_1['class'] = 1\n",
    "\n",
    "news_2 = pd.read_csv(r'C:\\Users\\darias\\Desktop\\news_2.csv',  sep=\";\", decimal=\",\", \n",
    "                   skiprows=[1,2,3,4], low_memory=False, on_bad_lines='skip').sort_values(by=[\"CODE\"])\n",
    "news_2['class'] = 2\n",
    "\n",
    "news_3 = pd.read_csv(r'C:\\Users\\darias\\Desktop\\news_3.csv',  sep=\";\", decimal=\",\", \n",
    "                   skiprows=[1,2,3,4], low_memory=False, on_bad_lines='skip').sort_values(by=[\"CODE\"])\n",
    "news_3['class'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_TYPE_TOKEN_RATIO_LEMMAS</th>\n",
       "      <th>L_PROPER_NAME</th>\n",
       "      <th>L_PERSONAL_NAME</th>\n",
       "      <th>L_PUNCT</th>\n",
       "      <th>L_PUNCT_COM</th>\n",
       "      <th>L_PUNCT_SEMC</th>\n",
       "      <th>L_PUNCT_COL</th>\n",
       "      <th>L_PUNCT_DASH</th>\n",
       "      <th>L_CONT_A</th>\n",
       "      <th>L_FUNC_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SY_NON_FINITE</th>\n",
       "      <th>SY_QUOTATIONS</th>\n",
       "      <th>SY_EXCLAMATION</th>\n",
       "      <th>SY_QUESTION</th>\n",
       "      <th>SY_ELLIPSES</th>\n",
       "      <th>SY_POSITIONING</th>\n",
       "      <th>SY_CONDITIONAL</th>\n",
       "      <th>SY_IMPERATIVE</th>\n",
       "      <th>SY_AMPLIFIED_SENT</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.512415</td>\n",
       "      <td>0.031603</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>0.142212</td>\n",
       "      <td>0.072235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.632054</td>\n",
       "      <td>0.209932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>0.527638</td>\n",
       "      <td>0.031826</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.144054</td>\n",
       "      <td>0.051926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.207705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.493783</td>\n",
       "      <td>0.087034</td>\n",
       "      <td>0.055062</td>\n",
       "      <td>0.206039</td>\n",
       "      <td>0.087034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564831</td>\n",
       "      <td>0.223801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.039076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>0.649573</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165217</td>\n",
       "      <td>0.052174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>0.593939</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.534527</td>\n",
       "      <td>0.112532</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626598</td>\n",
       "      <td>0.189258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.538043</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.148571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>0.575610</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.185366</td>\n",
       "      <td>0.068293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25676 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      L_TYPE_TOKEN_RATIO_LEMMAS  L_PROPER_NAME  L_PERSONAL_NAME   L_PUNCT  \\\n",
       "59                     0.512415       0.031603         0.009029  0.142212   \n",
       "4070                   0.527638       0.031826         0.023451  0.144054   \n",
       "964                    0.493783       0.087034         0.055062  0.206039   \n",
       "5385                   0.649573       0.017094         0.000000  0.085470   \n",
       "3113                   0.600000       0.086957         0.000000  0.165217   \n",
       "...                         ...            ...              ...       ...   \n",
       "5997                   0.593939       0.103030         0.066667  0.187879   \n",
       "87                     0.534527       0.112532         0.058824  0.176471   \n",
       "2498                   0.538043       0.070652         0.076087  0.168478   \n",
       "6615                   0.617143       0.114286         0.051429  0.182857   \n",
       "3937                   0.575610       0.063415         0.029268  0.185366   \n",
       "\n",
       "      L_PUNCT_COM  L_PUNCT_SEMC  L_PUNCT_COL  L_PUNCT_DASH  L_CONT_A  \\\n",
       "59       0.072235           0.0     0.000000      0.004515  0.632054   \n",
       "4070     0.051926           0.0     0.001675      0.010050  0.603015   \n",
       "964      0.087034           0.0     0.001776      0.000000  0.564831   \n",
       "5385     0.025641           0.0     0.000000      0.000000  0.709402   \n",
       "3113     0.052174           0.0     0.017391      0.000000  0.643478   \n",
       "...           ...           ...          ...           ...       ...   \n",
       "5997     0.060606           0.0     0.018182      0.000000  0.654545   \n",
       "87       0.069054           0.0     0.005115      0.000000  0.626598   \n",
       "2498     0.043478           0.0     0.005435      0.005435  0.510870   \n",
       "6615     0.022857           0.0     0.005714      0.000000  0.662857   \n",
       "3937     0.068293           0.0     0.014634      0.000000  0.619512   \n",
       "\n",
       "      L_FUNC_A  ...  SY_NON_FINITE  SY_QUOTATIONS  SY_EXCLAMATION  \\\n",
       "59    0.209932  ...       0.004515       0.000000             0.0   \n",
       "4070  0.207705  ...       0.005025       0.000000             0.0   \n",
       "964   0.223801  ...       0.014210       0.039076             0.0   \n",
       "5385  0.196581  ...       0.000000       0.000000             0.0   \n",
       "3113  0.191304  ...       0.008696       0.034783             0.0   \n",
       "...        ...  ...            ...            ...             ...   \n",
       "5997  0.157576  ...       0.012121       0.030303             0.0   \n",
       "87    0.189258  ...       0.005115       0.020460             0.0   \n",
       "2498  0.184783  ...       0.016304       0.000000             0.0   \n",
       "6615  0.148571  ...       0.005714       0.057143             0.0   \n",
       "3937  0.195122  ...       0.004878       0.048780             0.0   \n",
       "\n",
       "      SY_QUESTION  SY_ELLIPSES  SY_POSITIONING  SY_CONDITIONAL  SY_IMPERATIVE  \\\n",
       "59       0.000000     0.000000        0.000000        0.000000       0.000000   \n",
       "4070     0.000000     0.001675        0.000000        0.000000       0.000000   \n",
       "964      0.003552     0.001776        0.000000        0.003552       0.000000   \n",
       "5385     0.000000     0.000000        0.000000        0.000000       0.000000   \n",
       "3113     0.000000     0.000000        0.000000        0.000000       0.000000   \n",
       "...           ...          ...             ...             ...            ...   \n",
       "5997     0.000000     0.000000        0.000000        0.000000       0.000000   \n",
       "87       0.000000     0.000000        0.005115        0.000000       0.002558   \n",
       "2498     0.000000     0.010870        0.000000        0.000000       0.000000   \n",
       "6615     0.000000     0.000000        0.000000        0.000000       0.000000   \n",
       "3937     0.000000     0.000000        0.009756        0.000000       0.000000   \n",
       "\n",
       "      SY_AMPLIFIED_SENT  class  \n",
       "59                  0.0      1  \n",
       "4070                0.0      1  \n",
       "964                 0.0      0  \n",
       "5385                0.0      3  \n",
       "3113                0.0      2  \n",
       "...                 ...    ...  \n",
       "5997                0.0      2  \n",
       "87                  0.0      2  \n",
       "2498                0.0      1  \n",
       "6615                0.0      3  \n",
       "3937                0.0      2  \n",
       "\n",
       "[25676 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = [news_0, news_1, news_2, news_3]\n",
    "data = pd.concat(frames).drop([\"CODE\"], axis=1)\n",
    "data = data.sample(frac = 1)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"class\"], axis=1)\n",
    "y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.1, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "sc = StandardScaler()\n",
    "normed_train_data = pd.DataFrame(sc.fit_transform(X_train), columns = X.columns)\n",
    "normed_test_data = pd.DataFrame(sc.fit_transform(X_test), columns = X.columns)\n",
    "normed_val_data = pd.DataFrame(sc.fit_transform(X_val), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categories\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(y_train.reshape(-1, 1))\n",
    "train_l = encoder.transform(y_train.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(y_val.reshape(-1, 1))\n",
    "val_l = encoder.transform(y_val.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(y_test.reshape(-1, 1))\n",
    "test_l = encoder.transform(y_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    x = Input(shape=(101), dtype=tf.float32)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=x, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=\"Adam\", loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 101)]             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 408\n",
      "Trainable params: 408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2375 - accuracy: 0.8306 - val_loss: 0.2280 - val_accuracy: 0.8288\n",
      "Epoch 2/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2366 - accuracy: 0.8314 - val_loss: 0.2298 - val_accuracy: 0.8191\n",
      "Epoch 3/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2361 - accuracy: 0.8324 - val_loss: 0.2289 - val_accuracy: 0.8230\n",
      "Epoch 4/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2356 - accuracy: 0.8329 - val_loss: 0.2293 - val_accuracy: 0.8288\n",
      "Epoch 5/10\n",
      "1284/1284 [==============================] - 1s 975us/step - loss: 0.2352 - accuracy: 0.8323 - val_loss: 0.2273 - val_accuracy: 0.8327\n",
      "Epoch 6/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2349 - accuracy: 0.8338 - val_loss: 0.2274 - val_accuracy: 0.8210\n",
      "Epoch 7/10\n",
      "1284/1284 [==============================] - 1s 967us/step - loss: 0.2345 - accuracy: 0.8337 - val_loss: 0.2267 - val_accuracy: 0.8249\n",
      "Epoch 8/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2344 - accuracy: 0.8342 - val_loss: 0.2264 - val_accuracy: 0.8249\n",
      "Epoch 9/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2341 - accuracy: 0.8352 - val_loss: 0.2250 - val_accuracy: 0.8288\n",
      "Epoch 10/10\n",
      "1284/1284 [==============================] - 1s 1ms/step - loss: 0.2339 - accuracy: 0.8358 - val_loss: 0.2269 - val_accuracy: 0.8230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230604cba60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(normed_train_data, train_l, batch_size = 16, epochs = 10, verbose=1, validation_data=(normed_val_data, val_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 875us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(normed_test_data).argmax(axis=1)\n",
    "encoder.fit(y_pred.reshape(-1, 1))\n",
    "y_pred_one_hot = encoder.transform(y_pred.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75       355\n",
      "           1       0.88      0.90      0.89      1669\n",
      "           2       0.81      0.84      0.83      1303\n",
      "           3       0.82      0.78      0.80      1295\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      4622\n",
      "   macro avg       0.82      0.81      0.82      4622\n",
      "weighted avg       0.84      0.84      0.84      4622\n",
      " samples avg       0.84      0.84      0.84      4622\n",
      "\n",
      "\n",
      "\n",
      "=== Accuracy Score ===\n",
      "0.8357853742968412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(test_l, y_pred_one_hot))\n",
    "print('\\n')\n",
    "print(\"=== Accuracy Score ===\")\n",
    "print(accuracy_score(test_l, y_pred_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = encoder.inverse_transform(test_l).flatten()\n",
    "y_pred = encoder.inverse_transform(y_pred_one_hot).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred, normalize=\"true\", labels= ['0', '1', '2', '3'], save=True,\n",
    "directory=r'C:\\Users\\darias\\Desktop\\\\', filename='LogisticRegression.png', title='Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0a2faa82db20f947920d9ade35461cfd3d45cac6510ce168f7e2b5afcc8f08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
